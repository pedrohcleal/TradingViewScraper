**Desafio T√©cnico de Web Scraping**

### Objetivo
Desenvolver um scraper em **Python** para coletar dados de livros dispon√≠veis no site [Books to Scrape](https://books.toscrape.com/) utilizando **Selenium** ou **BeautifulSoup**.

O prop√≥sito do desafio √©:
- Realizar scraping de m√∫ltiplas p√°ginas.
- Validar os dados coletados com **Pydantic**.
- Exibir os dados em **DTOs** validados.
- Estruturar o projeto de forma organizada.
- Publicar o c√≥digo em um reposit√≥rio p√∫blico no GitHub.

---

### **Requisitos do Projeto**

1. **Dados a serem extra√≠dos de cada livro:**
   - Nome do livro.
   - Link da imagem da capa.
   - Pre√ßo do livro.
   - Quantidade de estrelas.
   - Disponibilidade em estoque (sim/n√£o).

2. **Percorrer todas as p√°ginas:**
   O scraper deve navegar por todas as p√°ginas do site at√© coletar todos os dados.

3. **Valida√ß√£o dos dados com Pydantic:**
   - Crie uma classe DTO utilizando o Pydantic.
   - Valide cada livro coletado.

4. **Imprimir os DTOs validados:**
   Exiba os dados formatados no console.

5. **Uso de Selenium ou BeautifulSoup:**
   - Utilize **Selenium** como primeira op√ß√£o (mais f√°cil, por√©m mais lento).
   - BeautifulSoup pode ser usado como alternativa.

6. **Publicar no GitHub:**
   - Estruture o c√≥digo em um projeto organizado.
   - Crie um reposit√≥rio p√∫blico no GitHub com um README detalhado.

---

### Estrutura Sugerida do Projeto

```
books_scraper/
‚îÇ
‚îú‚îÄ‚îÄ chrome_config.py       # Configura√ß√£o padr√£o do ChromeDriver (fornecida abaixo)
‚îú‚îÄ‚îÄ dto.py                 # Defini√ß√£o do DTO com Pydantic
‚îú‚îÄ‚îÄ scraper.py             # L√≥gica principal do scraping
‚îú‚îÄ‚îÄ main.py                # Ponto de entrada do projeto
‚îî‚îÄ‚îÄ requirements.txt       # Depend√™ncias do projeto
```

---

### Configura√ß√£o do Selenium
O arquivo `chrome_config.py` cont√©m a configura√ß√£o padr√£o para o **ChromeDriver** usando **webdriver_manager**. 

#### **chrome_config.py**
```python
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.webdriver import WebDriver
from webdriver_manager.chrome import ChromeDriverManager
from selenium import webdriver
from contextlib import contextmanager


@contextmanager
def create_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless") # comentar essa linha para ver as itera√ß√µes no chrome
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-notifications")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--disable-extensions")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--disable-animations")
    chrome_options.add_argument("--disable-cache")
    chrome_options.add_argument("--disable-prefetch")

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    try:
        yield driver
    finally:
        print('fim do chromedriver')
        driver.quit()
```

---

### Como Usar a Configura√ß√£o

No seu arquivo `scraper.py`, importe a configura√ß√£o acima e utilize o **context manager** para inicializar o ChromeDriver:

```python
from chrome_config import create_driver

with create_driver() as driver:
    driver.get("https://books.toscrape.com/")
    # Escreva aqui a l√≥gica de scraping
```

---

### Passos Finais

1. **Instalar as depend√™ncias:**
   Utilize um arquivo `requirements.txt` para gerenciar as bibliotecas:

   ```txt
   selenium
   pydantic
   webdriver_manager
   beautifulsoup4  # Opcional, se utilizar BS4
   ```

2. **Executar o projeto localmente:**
   Certifique-se de que todas as depend√™ncias estejam instaladas:

   ```bash
   pip install -r requirements.txt
   python main.py
   ```

3. **Publicar no GitHub:**
   - Crie um reposit√≥rio p√∫blico.
   - Fa√ßa commit do projeto e adicione um README explicando o que o projeto faz e como rodar.

---

### B√¥nus
Adicione instru√ß√µes no README sobre como instalar e rodar o projeto em qualquer ambiente.

Bom desafio! üöÄ
